{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Graphs - Symbolic Computation\n",
    "*Christoph Heindl 2017, https://github.com/cheind/py-cgraph/*\n",
    "\n",
    "This is part two in a series about computational graphs and their applications. The first part covered theoretical foundations of computational graphs and associated algorithms to perform forward function evaluation and backward derivative computations.\n",
    "\n",
    "This part will focus on developing Python code that allows numeric and symbolic differentiation of arbitrary (real valued) functions.\n",
    "\n",
    "\n",
    "## CGraph \n",
    "\n",
    "CGraph is the name of the Python library to be developed during the remainder of this notebook. While the code inside the notebook is functional a separate, self-contained and enhanced implementation of CGraph is available [cgraph.py](../cgraph.py). \n",
    "\n",
    "CGraph performs numeric and symbolic differentiation using backpropagation.\n",
    "\n",
    "```Python\n",
    "import cgraph as cg\n",
    "\n",
    "x = cg.Symbol('x')\n",
    "y = cg.Symbol('y')\n",
    "z = cg.Symbol('z')\n",
    "\n",
    "f = (x * y + 3) / (z - 2)\n",
    "\n",
    "# Evaluate function\n",
    "cg.value(f, {x:2, y:3, z:3}) # 9.0\n",
    "\n",
    "# Partial derivatives (numerically)\n",
    "d = cg.numeric_gradient(f, {x:2, y:3, z:3})\n",
    "d[x] # df/dx 3.0\n",
    "d[z] # df/dz -9.0\n",
    "\n",
    "# Partial derivatives (symbolically)\n",
    "d = cg.symbolic_gradient(f)\n",
    "cg.simplify(d[x]) # (y*(1/(z - 2)))\n",
    "cg.value(d[x], {x:2, y:3, z:3}) # 3.0\n",
    "\n",
    "# Higher order derivatives\n",
    "ddx = cg.symbolic_gradient(d[x])\n",
    "cg.simplify(ddx[y]) # ddf/dxdy\n",
    "# (1/(z - 2))\n",
    "```\n",
    "\n",
    "Python 3.5 will be used for development. The reader is assumed to be familiar with its concepts including generators and decorators. Also a technique called monkey patching will be used to iteratively refine classes already introduced.\n",
    "\n",
    "### Expression trees\n",
    "\n",
    "Before diving into code, we need to cover the concept of [expression trees](https://en.wikipedia.org/wiki/Binary_expression_tree). Expression trees will be used to represent function decompositions in Python code to be developed. While there are not a fundamentally new concept they deserve some words at this point.\n",
    "\n",
    "An expression tree is similar to the computational graphs introduced, but the arrows by default point backwards. It turns out that constructing function expression in a tree like manner (top node is the function itself, function parameters are leafs) simplifies development dramatically.\n",
    "\n",
    "Take the CG of the toy example used $f(x,y)=(x+y)x$\n",
    "\n",
    "<img src=\"intro_0.png\" width=\"400\">\n",
    "\n",
    "The following expression tree represents the same function\n",
    "\n",
    "<img src=\"exp_tree.png\" width=\"400\">\n",
    "\n",
    "Notice that we now have a tree like structure. Our root node is the final operation to be executed to receive the result of $f(x,y)$. Also notice that $x$ shows up twice. Finding the value of an expression tree requires to compute values for nodes in lower layers first and bubble information up towards the root node. Backpropagation on the other hand ist just a matter of following the forward edges. Again, when computing derivatives, a summation over all paths from the top that lead to a given node will be performed.\n",
    "\n",
    "### Representing expression trees\n",
    "First we need to come up with a way to represent expression that were introducted in the previous part. trees in Python code. Naturally, we will have base class `Node` that manages child references and derived classes that actually implement operations, symbols and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    def __init__(self, nary=0):\n",
    "        self.children = [None]*nary\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node for now just tracks references to its children. Note that operations can be binary (e.g. addition), unary (e.g cosine) or don't have children at all (e.g. symbols). We can also think of n-ary functions such as summation. Next, we'll define the leaf nodes Symbol and Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Symbol(Node):\n",
    "\n",
    "    def __init__(self, name):\n",
    "        super(Symbol, self).__init__(nary=0)\n",
    "        self.name = name\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.name)            \n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.name == other.name      \n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Symbols are identified by their name, like  $x$. They don't have any children. When printed we print the name of the symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Constant(Node):\n",
    "\n",
    "    def __init__(self, value):\n",
    "        super(Constant, self).__init__(nary=0)\n",
    "        self.value = value\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants are 'immutable' values. Next we start to add operations. For this notebook we will provide addition, multiplication. cgraph.py has more operations defined and once you know how to implement them it will be easy for you to add new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Add(Node):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Add, self).__init__(nary=2)\n",
    "\n",
    "    def __str__(self):\n",
    "        return '({}+{})'.format(str(self.children[0]), str(self.children[1]))\n",
    "    \n",
    "class Mul(Node):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mul, self).__init__(nary=2)\n",
    "\n",
    "    def __str__(self):\n",
    "        return '({}*{})'.format(str(self.children[0]), str(self.children[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Add` and `Mul` don't do much yet expect that stating that they are binary functions plus some pretty printing (recursively calling `__str__` on its children). Next, well just have a helper function that builds our toy function $f(x,y)=(x+y)x$. This looks a bit clumsy right now but we'll improve the syntax as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((x+y)*x)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_f(x, y): \n",
    "    a = Add()\n",
    "    a.children[0] = x\n",
    "    a.children[1] = y\n",
    "    \n",
    "    m = Mul()\n",
    "    m.children[0] = a\n",
    "    m.children[1] = x\n",
    "    \n",
    "    return m\n",
    "\n",
    "x = Symbol('x')\n",
    "y = Symbol('y')\n",
    "f = gen_f(x, y)\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing function values\n",
    "\n",
    "Next we'll turn our attention towards computing values of functions represented as expression trees. As mentioned earlier to compute the value, we'll need to bubble up information from layers further down in hierarchy up to the root. Traversing expression trees can be performed in multiple ways. What we are looking for is [depth-first-search](https://en.wikipedia.org/wiki/Depth-first_search) in [post-order](https://en.wikipedia.org/wiki/Tree_traversal). There are many ways to implement the traversal, i've chosen the recursive generator approach because of its shortness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def postorder(node):\n",
    "    for c in node.children:\n",
    "        yield from postorder(c)\n",
    "    yield node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x, y, (x+y), x, ((x+y)*x)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n for n in postorder(f)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, children are evaluated before their parents. Excactly what's needed for computing function values. Next, define the method that computes the forward pass, i.e the value of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def values(f, fargs):\n",
    "    \"\"\"Returns a dictionary of computed values for each node in the expression tree including `f`.\"\"\"\n",
    "    v = {}\n",
    "    v.update(fargs)\n",
    "    for n in postorder(f):\n",
    "        if not n in v:\n",
    "            v[n] = n.compute_value(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method calls for each node `compute_value(values)` and expects the node to return its value. Since we haven't defined this function for our nodes yet, it's time to do so. Also note that `fargs` will be assumed to contain the values for the symbols in the expression tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Monkey patching for compute_value\n",
    "Symbol.compute_value = lambda self, values: values[self]\n",
    "Constant.compute_value = lambda self, values : self.value\n",
    "Add.compute_value = lambda self, values: values[self.children[0]] + values[self.children[1]]\n",
    "Mul.compute_value = lambda self, values: values[self.children[0]] * values[self.children[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After monkey patching in `compute_value` for all nodes we can evaluate `f` by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values(f, {x:2, y:3})[f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `values` computes all the values even for intermediate nodes we need to add `[f]` as a postfix. Just accessing the value of `f` will however be so common task that we provide a shortcut for it named `value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def value(f, fargs):\n",
    "    return values(f, fargs)[f]\n",
    "\n",
    "value(f, {x:2, y:3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntactic sugar\n",
    "\n",
    "Before continuing it makes sense to use Python's internal methods for 'overloading' the `+` and `*` operation for Nodes. First, we'll define a decorator that will wrap plain numbers to `Constants`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numbers import Number\n",
    "\n",
    "def wrap_args(func):\n",
    "    \"\"\"Wraps function arguments that are numbers as Constant objects.\"\"\"\n",
    "    def wrapped(*args, **kwargs):\n",
    "        new_args = []\n",
    "        for a in args:\n",
    "            if isinstance(a, Number):\n",
    "                a = Constant(a)\n",
    "            new_args.append(a)\n",
    "        return func(*new_args, **kwargs)\n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define some free functions that perform the 'lengthy' addition and multiplication. By convention these free functions will start with the prefix `sym_` (for symbolic). When adding new functionality you should always provide such a function (e.g `sym_pow, sym_cos`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@wrap_args\n",
    "def sym_add(x, y):\n",
    "    n = Add()\n",
    "    n.children[0] = x\n",
    "    n.children[1] = y\n",
    "    return n\n",
    "\n",
    "@wrap_args\n",
    "def sym_mul(x, y):\n",
    "    n = Mul()\n",
    "    n.children[0] = x\n",
    "    n.children[1] = y\n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we monkey patch `Node` to support `+` and `*` operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Node.__add__ = lambda self, other: sym_add(self, other)\n",
    "Node.__radd__ = lambda self, other: sym_add(other, self)\n",
    "Node.__mul__ = lambda self, other: sym_mul(self, other)\n",
    "Node.__rmul__ = lambda self, other: sym_mul(other, self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `__r*` methods are also overloaded so that expressions of the type `n*3` and `3*n` work equally well. With that we can rewrite `gen_f` introduced by simply saying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((x+y)*x)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = (x + y)*x\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing numeric derivatives\n",
    "\n",
    "Next we will turn our attention to the backpropagation for computing numerical derivatives. For this we first need another traversal, one that visits all nodes on the same level before moving on to the next level. Such a traversal is called [breadth-first-search](https://en.wikipedia.org/wiki/Breadth-first_search) and it can also be implemented in numerous ways.\n",
    "\n",
    "The way it is implemented here is based on a generator that uses a queue. However when performing backpropagation, we'd like to communicate values back to the generator for each children of the current node. We then expect the handed values to be passed to us when we visit the corresponding child. Doing so turns the generator into [co-routine](https://en.wikipedia.org/wiki/Coroutine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bfs(node, node_data):\n",
    "    q = [(node, node_data)]\n",
    "    while q:\n",
    "        t = q.pop(0)\n",
    "        node_data = yield t\n",
    "        for idx, c in enumerate(t[0].children):\n",
    "            q.append((c, node_data[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, `numeric_gradient` is presented. It takes an expression tree and function arguments for the contained symbols and computes all numeric partial derivatives with respect to the root node passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def numeric_gradient(f, fargs):\n",
    "    vals = values(f, fargs)\n",
    "    derivatives = defaultdict(int) # by default 0 is the derivative for unknown nodes.\n",
    "\n",
    "    gen = bfs(f, 1)\n",
    "    try:\n",
    "        n, in_grad = next(gen)\n",
    "        while True:\n",
    "            derivatives[n] += in_grad\n",
    "            local_grad = n.compute_gradient(vals)\n",
    "            n, in_grad = gen.send([l*in_grad for l in local_grad])\n",
    "    except StopIteration:\n",
    "        return derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, numeric_gradient performs a forward pass to compute all function values. Next, breadth-first-search is kicked of by f and a value of 1. Then for each node visited we accumulate incoming partial derivatives send along the edges. Next, the local isolated gradient is computed. We communicate back the local gradient times incoming partial derivative as explained in the backpropagation introduction before. Finally a dictionary of partial derivatives for each operation is returned.\n",
    "\n",
    "Also note that we need to provide implementations of `compute_gradient(values)` for each node. `compute_gradient` is expected to take in a values dictionary and return the isolated partial derivative for every children in array form. As always, lets monkey patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Monkey patch for compute_gradient\n",
    "Symbol.compute_gradient = lambda self, values: [] # Nothing todo\n",
    "Constant.compute_gradient = lambda self, values: [] # Nothing todo\n",
    "\n",
    "Add.compute_gradient = lambda self, values: [1, 1] # dx+y/dx = 1, dx+y/dy = 1\n",
    "Mul.compute_gradient = lambda self, values: [values[self.children[1]], values[self.children[0]]] # dx*y/dx = y, dx*y/dy = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The isolated gradients for `Add` and `Mul` should look familiar to you. If not, go back to the introduction on computational graphs. With that in place we can now compute numeric derivatives like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {x: 7, y: 2, (x+y): 2, ((x+y)*x): 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_gradient(f, {x:2, y:3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see $\\frac{\\mathrm{d}f(x,y)}{\\mathrm{d}x}\\Bigr|_{\\substack{x=2\\\\y=3}} = 7$ and $\\frac{\\mathrm{d}f(x,y)}{\\mathrm{d}y}\\Bigr|_{\\substack{x=2\\\\y=3}} = 2$. But the dictionary provides more, also the derivative w.r.t $(x+y)$ is given! Some more examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {x: 4, y: 6, ((x*x)+(y*y)): 1, (y*y): 1, (x*x): 1})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_gradient(x*x+y*y, {x:2, y:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {((x+3)*(y+4)): 25,\n",
       "             x: 175,\n",
       "             z: 350,\n",
       "             ((((x+3)*(y+4))*z)*z): 1,\n",
       "             3: 175,\n",
       "             (x+3): 175,\n",
       "             y: 125,\n",
       "             (y+4): 125,\n",
       "             (((x+3)*(y+4))*z): 5,\n",
       "             4: 125})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = Symbol('z')\n",
    "numeric_gradient((x+3)*(y+4)*z*z, {x:2, y:3, z:5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing symbolic derivatives\n",
    "\n",
    "Now that we can compute numerica derivates one might wonder if we could do the same symbolically, i.e instead of returning a number we return some expression tree. Clearly such a feature would be beneficial as it would allow computation of higher order derivatives. Additionally, pre-factoring the derivative expressions might be favorable when invoking the derivative evaluation multiple times.\n",
    "\n",
    "Turns out modifying the numeric gradient computation for symbolic computation is straight forward. All that needs to be done is to return appropriate `Node`s instead of numeric values. Infact with the overloaded `+` and `*` operations in place for nodes, the symbolic gradient computation looks nearly identical to `numeric_gradient` as defined earlier.\n",
    "\n",
    "Here it is, `symbolic_gradient`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def symbolic_gradient(f):\n",
    "    derivatives = defaultdict(lambda: Constant(0))\n",
    "    \n",
    "    gen = bfs(f, Constant(1))\n",
    "    try:\n",
    "        n, in_grad = next(gen) # Need to use edge info when expressions are reused!\n",
    "        while True:\n",
    "            derivatives[n] = derivatives[n] + in_grad\n",
    "            local_grad = n.symbolic_gradient()\n",
    "            n, in_grad = gen.send([l * in_grad for l in local_grad])\n",
    "    except StopIteration:\n",
    "        return derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only differences: we use `Constant` instead of numbers directly and a method to be defined `symbolic_gradient` is invoked. One can probably guess that the operations `+` and `*` call the corresponding overloads for `Node` objects introduced earlier. As always, let's monkey patch for `symbolic_gradient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Monkey patch for symbolic_gradient\n",
    "Symbol.symbolic_gradient = lambda self: [] # Nothing todo\n",
    "Constant.symbolic_gradient = lambda self: [] # Nothing todo\n",
    "\n",
    "Add.symbolic_gradient = lambda self: [Constant(1), Constant(1)] # dx+y/dx = 1, dx+y/dy = 1\n",
    "Mul.symbolic_gradient = lambda self: [self.children[1], self.children[0]] # dx*y/dx = y, dx*y/dy = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, replace numbers by Constants and for `Mul` just return the opposite child expression. Let's test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.symbolic_gradient.<locals>.<lambda>>,\n",
       "            {x: ((0+((x+y)*1))+(1*(x*1))),\n",
       "             y: (0+(1*(x*1))),\n",
       "             (x+y): (0+(x*1)),\n",
       "             ((x+y)*x): (0+1)})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbolic_gradient(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at $x$. It claims derivative of $f$ with respect to $x$ is equal to `((0 + ((x + y)*1)) + (1*(x*1)))`. After massaging the terms you indeed find that this is the same as $2x+y$. Although not very readable, the reported results are correct. Something we will tackle in the next section when we begin to simplify expressions. \n",
    "\n",
    "Since the returned dictionary contains expressions, we can apply all our arsenal of functions developed so far onto them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/dx at (x=2,y=3) is 7\n",
      "df/dy at (x=2,y=3) is 2\n",
      "ddf/dxdx at (x=2,y=3) is 2\n",
      "ddf/dxdy at (x=2,y=3) is 1\n",
      "ddf/dydx at (x=2,y=3) is 1\n",
      "ddf/dydy at (x=2,y=3) is 0\n"
     ]
    }
   ],
   "source": [
    "d = symbolic_gradient(f)\n",
    "print('df/dx at (x=2,y=3) is {}'.format(value(d[x], {x:2, y:3})))\n",
    "print('df/dy at (x=2,y=3) is {}'.format(value(d[y], {x:2, y:3})))\n",
    "\n",
    "# Let's try second order derivatives\n",
    "ddx = symbolic_gradient(d[x])\n",
    "ddy = symbolic_gradient(d[y])\n",
    "print('ddf/dxdx at (x=2,y=3) is {}'.format(value(ddx[x], {x:2, y:3})))\n",
    "print('ddf/dxdy at (x=2,y=3) is {}'.format(value(ddx[y], {x:2, y:3})))\n",
    "print('ddf/dydx at (x=2,y=3) is {}'.format(value(ddy[x], {x:2, y:3})))\n",
    "print('ddf/dydy at (x=2,y=3) is {}'.format(value(ddy[y], {x:2, y:3})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new operations\n",
    "\n",
    "Adding new operations to CGraph is not hard. The following recipe sums up the necessary steps.\n",
    " 1. Add a new class inheriting `Node`\n",
    " 1. Add implementations for `compute_value`, `symbolic_gradient` and optionally for `compute_gradient`\n",
    " 1. Provide one or more free function with prefix `sym_*` that connects arguments as inputs for your operation. Use `@wrap_args` where appropriate.\n",
    " 1. Optionally provide and implementation for `__str__`\n",
    " 1. Optionally provide new `__*__` methods in `Node` to support improved syntax delegating to `sym_*` methods.\n",
    " \n",
    "Note that `compute_gradient` is optional, as it can always be mimicked by `symbolic_gradient` followed by `value`. \n",
    "\n",
    "A word of caution: when computing numeric gradients through `compute_gradient` you might find yourself in a position of potentially dividing by zero or raising any other math expection. When this happens on path you are even not interested in, gradient computation will stop. For example consider $f(x,y) = x^y$ and let $x=-1, y=2$. Then when evaluating the gradient for $y$ you will find that it corresponds to $x^y*log(x)$. Unfortunately $x$ is negative and so the value can not be computed. Python raises an exception and gradient computation fails.\n",
    "\n",
    "CGraph handles this by using `NAN`s instead of exceptions. Almost all operations that invoke `NAN`s result in `NAN`, so they propagate nicely. In [CGraph](../cgraph.py) a function named `nan_on_fail` is used to catch math exceptions and instead return `NAN`. See `Div` for example usage.\n",
    "\n",
    "### Expression simplification\n",
    "\n",
    "Earlier we saw that symbolic differentiation produces hardly readable expressions, such as `((0+((x+y)∗1))+(1∗(x∗1)))`. In this section we will see how to simplify such expressions. Not only will this improve readability but also performance as lesser nodes need to be evaluated (pays off especially when you invoke it many times after simplification).\n",
    "\n",
    "The way CGraph implements expression simplification is by traversing the computational graph, while trying to apply simplification rules. Each rule is given a node and may produce a simplier version of that node. The new node 'replaces' the old node in an expression tree that is formed in parallel. That means that we won't fiddle around with the original expression tree given, but rather generate a expression tree that represents a simplified version of the original one.\n",
    "\n",
    "First we will implement a rule filter decorator, a helper function and a single rule."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
